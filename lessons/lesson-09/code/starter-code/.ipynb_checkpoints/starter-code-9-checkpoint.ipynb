{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS_HK_15 | Class 09 | Introduction to Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Practice: Logit Function and Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".container { width:100% !important;}\n",
    ".plotly-graph-div.js-plotly-plot {margin:0 auto;}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logit_func(odds):\n",
    "    # uses a float (odds) and returns back the log odds (logit)\n",
    "    return np.log(odds)\n",
    "\n",
    "def sigmoid_func(logit):\n",
    "    # uses a float (logit) and returns back the probability\n",
    "    return 1. / (1 + np.exp(-logit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odds_set = [\n",
    "    5./1,\n",
    "    20./1,\n",
    "    1.1/1,\n",
    "    1.8/1,\n",
    "    1.6/1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Probabilities for each team\n",
    "# Your code here\n",
    "\n",
    "for odds in odds_set:\n",
    "    print(sigmoid_func(logit_func(odds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### College Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\n",
    "df = pd.read_csv('../../assets/dataset/collegeadmissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df['rank'], prefix='rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('admit').gpa.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group data together\n",
    "x1 = df[df.admit == 1]['gpa'].values\n",
    "x2 = df[df.admit == 0]['gpa'].values\n",
    "\n",
    "hist_data = [x1, x2]\n",
    "\n",
    "group_labels = ['Admited', 'Not Admited']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=0.05)\n",
    "fig['layout'].update(title='GPA')\n",
    "\n",
    "# Plot!\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genHist(the_df, colour_col, value_col, bin_size):\n",
    "    hist_data = []\n",
    "    for x in set(the_df[colour_col]):\n",
    "        hist_data.append(df[df[colour_col] == x][value_col].values)\n",
    "    group_labels = list(set(df['admit']))\n",
    "    fig = ff.create_distplot(hist_data, group_labels, bin_size=bin_size)\n",
    "    fig['layout'].update(title=value_col)\n",
    "    plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genHist(df, 'admit', 'gpa', 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "\n",
    "ft_list = ['gpa']\n",
    "\n",
    "lm.fit(df[ft_list], df['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lm.coef_\n",
    "print lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "\n",
    "ft_list = ['gpa', 'gre']\n",
    "\n",
    "lm.fit(df[ft_list], df['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lm.coef_\n",
    "print lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "\n",
    "ft_list = [\"rank_1\"]\n",
    "\n",
    "lm.fit(df[ft_list], df['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lm.coef_\n",
    "print lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "\n",
    "ft_list = df.columns[1:].tolist()\n",
    "\n",
    "lm.fit(df[ft_list], df['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.admit.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft_list.remove('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[ft_list]\n",
    "y = df[\"admit\"]\n",
    "lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = lm.predict(X)\n",
    "predicted_proba = lm.predict_proba(X)\n",
    "threshold = 0.75\n",
    "\n",
    "predicted_proba = [s[0] for s in predicted_proba]\n",
    "predicted_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_classes = [int(proba > threshold) for proba in predicted_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#threshold = 0.75\n",
    "accuracy_score(y, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#threshold = 0.5\n",
    "accuracy_score(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y, predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some code to walk through confusion matrices. It'll be useful for working through the Titanic problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the ROC curve is based on various thresholds: it shows with a false positive rate (x-axis) ~0, it also expects a true positive rate (y-axis) ~0 (the same, ish, for the top right hand of the figure).\n",
    "\n",
    "The second chart, which does not play with thesholds, shows the one true TPR and FPR point, joined to 0,0 and 1,1.\n",
    "\n",
    "The first chart will be more effective as you compare models and determine where the decision line should exist for the data. The second simplifies the first in case this idea of thresholds is confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(roc_curve(df[['admit']], predicted_classes)[0], roc_curve(df[['admit']], predicted_classes)[1], columns=[\"ROC\"])\n",
    "df_result[\"RandomGuess\"] = df_result.index\n",
    "\n",
    "df_result.iplot(x = \"ROC\", xTitle = \"False Positive Rate\", y = \"RandomGuess\", yTitle = \"True Positive Rate\", title = \"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the `roc_auc_score` function to calculate the area under these curves (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(df['admit'], predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(df['admit'], predicted_classes)\n",
    "title = (\"ROC Curve\" + \" - AUC: \" + \"{:.2f}\".format(auc_score))\n",
    "df_result.iplot(x = \"ROC\", xTitle = \"False Positive Rate\", y = \"RandomGuess\", yTitle = \"True Positive Rate\", title = title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Goals **\n",
    "\n",
    "1. Spend a few minutes determining which data would be most important to use in the prediction problem. You may need to create new features based on the data available. Consider using a feature selection aide in sklearn. But a worst case scenario; identify one or two strong features that would be useful to include in the model.\n",
    "2. Spend 1-2 minutes considering which _metric_ makes the most sense to optimize. Accuracy? FPR or TPR? AUC? Given the business problem (understanding survival rate aboard the Titanic), why should you use this metric?\n",
    "3. Build a tuned Logistic model. Be prepared to explain your design (including regularization), metric, and feature set in predicting survival using the tools necessary (such as a fit chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('../../assets/dataset/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.set_index('PassengerId', inplace=True)\n",
    "titanic = titanic.join(pd.get_dummies(titanic.Pclass, prefix=\"pclass\"))\n",
    "titanic['is_male'] = titanic.Sex.apply(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "titanic.groupby('Survived').Age.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['Age'] = titanic.groupby([\"Sex\", 'Pclass']).Age.transform(lambda x: x.fillna(x.mean()))\n",
    "titanic['had_parents'] = titanic.Parch.apply(lambda x: 1 if x > 0 else 0)\n",
    "titanic['had_siblings'] = titanic.SibSp.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Old Way\n",
    "from sklearn import grid_search, cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feature_set = titanic[['is_male', 'pclass_1', 'pclass_2', 'Fare', 'Age', 'had_parents', 'had_siblings']]\n",
    "\n",
    "para_dict = {'C': [10**-i for i in range(-5, 5)], 'class_weight': [None, 'balanced']},\n",
    "\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=para_dict,\n",
    "    cv=cross_validation.KFold(n=len(titanic), n_folds=10),\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "\n",
    "gs.fit(feature_set, titanic.Survived)\n",
    "gs.grid_scores_\n",
    "#print gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#New Way\n",
    "from sklearn import model_selection\n",
    "\n",
    "# use model_selection.GridSearchCV instead of grid_search.GridSearchCV\n",
    "gs = model_selection.GridSearchCV(    estimator=LogisticRegression(),\n",
    "    param_grid={'C': [10**-i for i in range(-5, 5)], 'class_weight': [None, 'balanced']},\n",
    "    cv=cross_validation.KFold(n=len(titanic), n_folds=10),\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "# same as before\n",
    "gs.fit(feature_set, titanic.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use cv_results_ instaed of grid_scores_\n",
    "# cv_results_ contians lots more info now\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.cv_results_[\"std_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_cv_result = zip([\"%.2f\" % x for x in gs.cv_results_[\"mean_test_score\"]], \n",
    "                   [round(x, 2) for x in gs.cv_results_[\"std_test_score\"]], \n",
    "                   gs.cv_results_[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_cv_result = zip([\"%.2f\" % x for x in gs.cv_results_[\"mean_test_score\"]], \n",
    "                   [round(x, 2) for x in gs.cv_results_[\"std_test_score\"]], \n",
    "                   gs.cv_results_[\"params\"])\n",
    "gs_cv_result = [{\"mean\":x[0], \"std\":x[1], \"C\":x[2][\"C\"], \"Weight\":x[2][\"class_weight\"]} for x in gs_cv_result]\n",
    "gs_cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same as the old one\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same as the old one\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.sample(2)[['is_male', 'pclass_1', 'pclass_2', 'Fare', 'Age', 'had_parents', 'had_siblings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.predict_proba(titanic.sample(2)[['is_male', 'pclass_1', 'pclass_2', 'Fare', 'Age', 'had_parents', 'had_siblings']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
