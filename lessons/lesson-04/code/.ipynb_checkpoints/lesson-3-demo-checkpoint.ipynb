{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Demos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality Demo\n",
    "http://hamelg.blogspot.com/2015/11/python-for-data-analysis-part-21.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = pd.read_csv(\"mtcars.csv\")\n",
    "mtcars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can uncomment each of the lines below to run that command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "# mtcars.mean()\n",
    "# mtcars.median()\n",
    "# mtcars.quantile(0.5)\n",
    "# mtcars.mode()\n",
    "# mtcars.std()\n",
    "# mtcars.median()\n",
    "# mtcars.quantile(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation matrix shows how well variables relate to each other in terms of simple linear regression. The value given si between -1 and 1.\n",
    "\n",
    "Values close to 1 indicate a strong positive correlation.\n",
    "Values close to 0 indicate weak to no correlation.\n",
    "Values close to -1 indicate a strong negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.go_offline()\n",
    "mtcars.corr().iplot(kind='heatmap',colorscale='spectral',\n",
    "             filename='cufflinks/simple-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import graph_objs\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode()\n",
    "cf.go_offline()\n",
    "\n",
    "df = mtcars[['cyl', 'mpg']]\n",
    "fig = FF.create_violin(df, data_header='mpg',group_header='cyl')\n",
    "iplot(fig, filename='cufflinks/violins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='cyl'\n",
    "y='mpg'\n",
    "# Unpack this! :D \n",
    "mtcars[[x, y]].set_index(x, append=True)[y].unstack().iplot(kind='box', boxpoints=\"suspectedoutliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the mean and median both give us some sense of the center of a distribution, they aren't always the same. The *median* gives us a value that **splits the data into two halves** while the *mean* is a **numeric average,** so extreme values can have a significant impact on the mean. \n",
    "\n",
    "In a symmetric distribution, the mean and median will be the same. Let's investigate with a density plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars[\"mpg\"].skew()  # Check skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars[\"mpg\"].kurt()  # Check kurtosis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore these two measures further, let's create some dummy data and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_data = np.random.normal(size=100000)\n",
    "skewed_data = np.concatenate((np.random.normal(size=35000)+2, \n",
    "                             np.random.exponential(size=65000)), \n",
    "                             axis=0)\n",
    "uniform_data = np.random.uniform(0,2, size=100000)\n",
    "peaked_data = np.concatenate((np.random.exponential(size=50000),\n",
    "                             np.random.exponential(size=50000)*(-1)),\n",
    "                             axis=0)\n",
    "\n",
    "data_df = pd.DataFrame({\"norm\":norm_data,\n",
    "                       \"skewed\":skewed_data,\n",
    "                       \"uniform\":uniform_data,\n",
    "                       \"peaked\":peaked_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = \"norm\"\n",
    "data_df[key].iplot(vline=[{'x': data_df[key].mean(), 'color': 'red'}, {'x':data_df[key].median(), 'color':'green'}],\n",
    "                      kind='histogram', filename='cufflinks/basic-histogram', line_color=\"black\")\n",
    "print( \"Kurtosis: \" + str(data_df[key].kurt()))\n",
    "print( \"Skewness: \" + str(data_df[key].skew()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"skewed\"\n",
    "data_df[key].iplot(vline=[{'x': data_df[key].mean(), 'color': 'red'}, {'x':data_df[key].median(), 'color':'green'}],\n",
    "                      kind='histogram', filename='cufflinks/basic-histogram', line_color=\"black\")\n",
    "print( \"Kurtosis: \" + str(data_df[key].kurt()))\n",
    "print( \"Skewness: \" + str(data_df[key].skew()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = \"peaked\"\n",
    "data_df[key].iplot(vline=[{'x': data_df[key].mean(), 'color': 'red'}, {'x':data_df[key].median(), 'color':'green'}],\n",
    "                      kind='histogram', filename='cufflinks/basic-histogram', line_color=\"black\")\n",
    "print( \"Kurtosis: \" + str(data_df[key].kurt()))\n",
    "print( \"Skewness: \" + str(data_df[key].skew()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"uniform\"\n",
    "data_df[key].iplot(vline=[{'x': data_df[key].mean(), 'color': 'red'}, {'x':data_df[key].median(), 'color':'green'}],\n",
    "                      kind='histogram', filename='cufflinks/basic-histogram', line_color=\"black\")\n",
    "print( \"Kurtosis: \" + str(data_df[key].kurt()))\n",
    "print( \"Skewness: \" + str(data_df[key].skew()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = np.random.normal(size=50)\n",
    "outliers = np.random.normal(15, size=3)\n",
    "combined_data = pd.DataFrame({\"combined\": np.concatenate((norm_data, outliers), axis=0)})\n",
    "comb = combined_data[\"combined\"] \n",
    "\n",
    "key = \"norm\"\n",
    "comb.iplot(vline=[{'x': comb.mean(), 'color': 'red'}, {'x':comb.median(), 'color':'green'}],\n",
    "                      kind='histogram', filename='cufflinks/basic-histogram', line_color=\"black\", bins=100)\n",
    "print( \"Kurtosis: \" + str(comb.kurt()))\n",
    "print( \"Skewness: \" + str(comb.skew()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the median tends to resist the effects of skewness and outliers, it is known a \"robust\" statistic. \n",
    "\n",
    "The median generally gives a better sense of the typical value in a distribution with significant skew or outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness and Kurtosis\n",
    "*Skewness* measures the **skew or asymmetry of a distribution** while *Kurtosis* measures the **\"peakedness\" of a distribution**. \n",
    "\n",
    "We won't go into the exact calculations behind these, but they are essentially just statistics that take the idea of variance a step further: while variance involves squaring deviations from the mean, skewness involves cubing deviations from the mean, and kurtosis involves raising deviations from the mean to the 4th power.\n",
    "\n",
    "Pandas has built in functions for checking skewness and kurtosis, df.skew() and df.kurt() respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the skewness of each of these distributions. \n",
    "\n",
    "Since skewness measures asymmetry, we'd expect to see low skewness for all of the distributions except the skewed one, because all the others are roughly symmetric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check kurtosis. Since kurtosis measures peakedness, we'd expect the flat (uniform) distribution to have low kurtosis while the distributions with sharper peaks should have higher kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output, the normally distributed data has a kurtosis near zero, the flat distribution has negative kurtosis, and the two pointier distributions have positive kurtosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-class exercises\n",
    "\n",
    "- http://chrisalbon.com/python/pandas_with_seaborn.html\n",
    "- https://stanford.edu/~mwaskom/software/seaborn/tutorial/distributions.html\n",
    "- https://stanford.edu/~mwaskom/software/seaborn/tutorial/categorical.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Variable Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class/Dummy Variables\n",
    "We want to represent categorical variables numerically, but we can't simply code them as 0=rural, 1=suburban, 2=urban because that would imply an **ordered relationship** between suburban and urban (suggesting that urban is somehow \"twice\" the suburban category, which doesn't make sense).\n",
    "\n",
    "Why do we only need **two dummy variables, not three?** Because two dummies capture all of the information about the Area feature, and implicitly defines rural as the reference level.\n",
    "\n",
    "In general, if you have a categorical feature with k levels, you create k-1 dummy variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create three dummy variables using get_dummies, then exclude the first dummy column\n",
    "my_categorical_var_dummies = pd.get_dummies(my_categorical_var, prefix='Area').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Predictors with Two Categories\n",
    "\n",
    "Up to now, all of our predictors have been numeric. What if one of our predictors was categorical?\n",
    "\n",
    "Let's create a new feature called \"Size,\" and randomly assign observations to be small or large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "# create a Series of booleans in which roughly half are True\n",
    "nums = np.random.rand(len(data))\n",
    "mask_large = nums > 0.5\n",
    "\n",
    "# initially set Size to small, then change roughly half to be large\n",
    "data['Size'] = 'small'\n",
    "data.loc[mask_large, 'Size'] = 'large'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scikit-learn, we need to represent all data numerically. \n",
    "\n",
    "If the feature only has two categories, we can simply create a dummy variable that represents the categories as a binary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a new Series called IsLarge\n",
    "data['IsLarge'] = data.Size.map({'small':0, 'large':1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Predictors with More than Two Categories\n",
    "\n",
    "Let's create a new feature called Area, and randomly assign observations to be rural, suburban, or urban:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# assign roughly one third of observations to each group\n",
    "nums = np.random.rand(len(data))\n",
    "mask_suburban = (nums > 0.33) & (nums < 0.66)\n",
    "mask_urban = nums > 0.66\n",
    "data['Area'] = 'rural'\n",
    "data.loc[mask_suburban, 'Area'] = 'suburban'\n",
    "data.loc[mask_urban, 'Area'] = 'urban'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to represent Area numerically, but we can't simply code it as 0=rural, 1=suburban, 2=urban because that would imply an ordered relationship between suburban and urban (and thus urban is somehow \"twice\" the suburban category).\n",
    "\n",
    "Instead, we create another dummy variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create three dummy variables using get_dummies, then exclude the first dummy column\n",
    "area_dummies = pd.get_dummies(data.Area, prefix='Area').iloc[:, 1:]\n",
    "\n",
    "# concatenate the dummy variable columns onto the original DataFrame (axis=0 means rows, axis=1 means columns)\n",
    "data = pd.concat([data, area_dummies], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5,6,7]\n",
    "s = pd.Series(l)\n",
    "d = pd.DataFrame(s)\n",
    "e = pd.DataFrame( pd.Series( [1,2,3,4,5,6,7 ] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
